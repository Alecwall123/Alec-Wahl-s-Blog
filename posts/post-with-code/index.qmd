---
title: "Post #2 Swiss Analysis "
author: "Alec Wahl"
date: "2023-11-05"
categories: [analysis]
---

![](images/swissflagdata.jpg){width="461" height="306"}

We are doing are going to analyze, a built in r-dataset called "swiss" this is a dataset takenfrom various socioeconomic indicators from Swiss Provinces.

```{r}
library(readr)
library(parsnip)
library(tidyverse)
library(ggplot2)

library(car)

library(lmtest)
library(broom)
library(dplyr)
library(leaps)
```

```{r}

data("swiss")

swiss %>%
  glimpse()

```

As seen above, this data has 6 variables, including various socioeconomic/fertility data from 47 French-speaking Provinces.

```{r}
swiss %>%
  ggplot(aes(x = Examination, y = Fertility)) +
  geom_point() +
  labs(title = "Fertility vs. Examination",
       x = "Examination",
       y = "Fertility")
swiss %>%
  ggplot(aes(x = Education, y = Fertility)) +
  geom_point() +
  labs(title = "Fertility vs. Education",
       x = "Examination",
       y = "Fertility")

```

Let's first graph fertility vs. examination, then fertility vs education. Due to the nature of education potentially affecting the score someone has on the examination, I will analyze whether adding an interaction term between these two predictor variables will improve the quality of my model.

```{r}

swissmodel1 <- linear_reg() %>%
  set_engine("lm") %>%
  fit(Fertility ~ Education+Examination, data = swiss)
tidy(swissmodel1)

swissmodel2 <- linear_reg() %>%
  set_engine("lm") %>%
  fit(Fertility ~ Education+Examination+Education:Examination, data = swiss)
tidy(swissmodel2)


```

As seen above, the p values of all the varibales is below 0.05 so this means these are probably, significant predictor variables. But our interaction term has a p-value of .528 which is well above our significance level of 0.05. So what we will now do is test the models fits against each other.

```{r}


anova_result <- anova(swissmodel1$fit,swissmodel2$fit) %>%
  tidy()%>%
  print()

swissmodel1$fit%>%
  vif()

```

The ANOVA performed above tells us to go with the model with fewer variables, or in other words, our model without the interaction term. The second test performed gives us the variation inflation factor of our two predictor variables from our original model. I ran this test because it allows us to know if there is collinearity between our predictor variables. Because both scores are below 5, we shouldn't have to worry about multicollinearity. This further supports the evidence that we probably do not need to add an interaction term.

## Source:

Project \"16P5\", pages 549--551 in

Mosteller, F. and Tukey, J. W. (1977) *Data Analysis and Regression: A Second Course in Statistics*. Addison-Wesley, Reading Mass
